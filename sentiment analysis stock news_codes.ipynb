{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1274067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for text pre-processing\n",
    "import re, string\n",
    "%pip install nltk\n",
    "# if run in VS, use %; if run in Jupter, delete the line above\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# SVM ML\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3637bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            1.1.0\n",
      "acnportal                          0.3.3\n",
      "aiohttp                            3.8.4\n",
      "aiosignal                          1.3.1\n",
      "alabaster                          0.7.12\n",
      "alpha-vantage                      2.3.1\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.1\n",
      "anaconda-project                   0.10.1\n",
      "anyio                              2.2.0\n",
      "appdirs                            1.4.4\n",
      "applaunchservices                  0.2.1\n",
      "appnope                            0.1.2\n",
      "appscript                          1.1.2\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "arrow                              0.13.1\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "async-timeout                      4.0.2\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              21.2.0\n",
      "autopep8                           1.5.7\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "beautifulsoup4                     4.12.2\n",
      "bigquery                           0.0.38\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.3.0\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.0.0\n",
      "bokeh                              2.4.1\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cached-property                    1.5.2\n",
      "cachetools                         5.2.0\n",
      "certifi                            2022.12.7\n",
      "cffi                               1.14.6\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.3\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "cmdstanpy                          1.1.0\n",
      "colorama                           0.4.4\n",
      "conda                              22.9.0\n",
      "conda-build                        3.23.3\n",
      "conda-content-trust                0+unknown\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             1.7.3\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "convertdate                        2.4.0\n",
      "cookiecutter                       1.7.2\n",
      "cryptography                       3.4.8\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.24\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.3.0\n",
      "dacktool                           0.0.7\n",
      "dask                               2021.10.0\n",
      "dbstream                           0.1.21\n",
      "debugpy                            1.4.1\n",
      "decorator                          5.1.0\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.4\n",
      "distributed                        2021.10.0\n",
      "docutils                           0.17.1\n",
      "echo                               0.5\n",
      "entrypoints                        0.3\n",
      "ephem                              4.1.4\n",
      "et-xmlfile                         1.1.0\n",
      "fast-histogram                     0.9\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.3.1\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        1.12\n",
      "fonttools                          4.25.0\n",
      "frozendict                         2.3.8\n",
      "frozenlist                         1.3.3\n",
      "fsspec                             2021.8.1\n",
      "future                             0.18.2\n",
      "gast                               0.4.0\n",
      "gensim                             4.3.2\n",
      "gevent                             21.8.0\n",
      "glob2                              0.7\n",
      "glue-core                          1.0.1\n",
      "glue-vispy-viewers                 0.12.2\n",
      "gmpy2                              2.0.8\n",
      "google-api-core                    2.15.0\n",
      "google-api-python-client           1.7.11\n",
      "google-auth                        2.26.2\n",
      "google-auth-httplib2               0.0.3\n",
      "google-auth-oauthlib               0.4.6\n",
      "google-cloud                       0.34.0\n",
      "google-cloud-bigquery              3.16.0\n",
      "google-cloud-bigquery-storage      2.24.0\n",
      "google-cloud-core                  2.4.1\n",
      "google-cloud-secret-manager        2.7.2\n",
      "google-crc32c                      1.5.0\n",
      "google-pasta                       0.2.0\n",
      "google-resumable-media             2.7.0\n",
      "googleapis-common-protos           1.62.0\n",
      "googleauthentication               0.0.17\n",
      "greenlet                           1.1.1\n",
      "grpc-google-iam-v1                 0.12.7\n",
      "grpcio                             1.60.0\n",
      "grpcio-status                      1.60.0\n",
      "h5py                               3.2.1\n",
      "HeapDict                           1.0.1\n",
      "holidays                           0.29\n",
      "html5lib                           1.1\n",
      "httplib2                           0.22.0\n",
      "idna                               3.2\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 4.8.1\n",
      "importlib-resources                6.0.0\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "install                            1.3.5\n",
      "intervaltree                       3.1.0\n",
      "investpy                           1.0.8\n",
      "ipykernel                          6.4.1\n",
      "ipython                            7.29.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipython-sql                        0.4.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.0\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "joblib                             1.3.2\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.8.1\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.2.1\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.8.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras                              2.9.0\n",
      "Keras-Preprocessing                1.1.2\n",
      "keyring                            23.1.0\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           14.0.1\n",
      "libcst                             1.1.0\n",
      "llvmlite                           0.37.0\n",
      "locket                             0.2.1\n",
      "LunarCalendar                      0.0.9\n",
      "lxml                               4.9.2\n",
      "Markdown                           3.3.7\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.4.3\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.10.0\n",
      "mpl-finance                        0.10.1\n",
      "mpl-scatter-density                0.7\n",
      "mplfinance                         0.12.9b1\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multidict                          6.0.4\n",
      "multipledispatch                   0.6.0\n",
      "multitasking                       0.0.11\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    0.4.3\n",
      "mysql-connector                    2.2.9\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.1.0\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.6.3\n",
      "nltk                               3.6.2\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.5\n",
      "numba                              0.54.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.22.4\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.2.0\n",
      "olefile                            0.46\n",
      "openpyxl                           3.0.9\n",
      "opt-einsum                         3.3.0\n",
      "packaging                          23.1\n",
      "pandas                             1.3.4\n",
      "pandas-datareader                  0.10.0\n",
      "pandocfilters                      1.4.3\n",
      "parso                              0.8.2\n",
      "partd                              1.2.0\n",
      "path                               16.0.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.4.0\n",
      "pip                                23.3.2\n",
      "pkginfo                            1.7.1\n",
      "plotly                             5.6.0\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "pmdarima                           2.0.3\n",
      "poyo                               0.5.0\n",
      "prettytable                        0.7.2\n",
      "prometheus-client                  0.11.0\n",
      "prompt-toolkit                     3.0.20\n",
      "prophet                            1.1.4\n",
      "proto-plus                         1.23.0\n",
      "protobuf                           4.25.2\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "py4j                               0.10.9.5\n",
      "pyarrow                            15.0.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.44.1\n",
      "pydocstyle                         6.1.1\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.10.0\n",
      "PyJWT                              2.1.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "PyMeeus                            0.5.12\n",
      "pyodbc                             4.0.0-unsupported\n",
      "PyOpenGL                           3.1.1a1\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyrsistent                         0.18.0\n",
      "PySocks                            1.7.1\n",
      "pyspark                            3.3.2\n",
      "pytest                             6.2.4\n",
      "python-dateutil                    2.8.2\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2023.3\n",
      "PyWavelets                         1.1.1\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.2.1\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.1.1\n",
      "QtPy                               1.10.0\n",
      "regex                              2021.8.3\n",
      "requests                           2.26.0\n",
      "requests-oauthlib                  1.3.1\n",
      "rope                               0.19.0\n",
      "rsa                                4.8\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "scikit-image                       0.18.3\n",
      "scikit-learn                       1.3.2\n",
      "scikit-learn-intelex               2021.20210714.100439\n",
      "scipy                              1.7.1\n",
      "seaborn                            0.11.2\n",
      "Send2Trash                         1.8.0\n",
      "setuptools                         58.0.4\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0\n",
      "smart-open                         6.4.0\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.2.1\n",
      "Sphinx                             4.2.0\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             5.1.5\n",
      "spyder-kernels                     2.1.3\n",
      "SQLAlchemy                         1.4.22\n",
      "sqlparse                           0.4.2\n",
      "statsmodels                        0.14.0\n",
      "sympy                              1.9\n",
      "tables                             3.6.1\n",
      "TBB                                0.2\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.0.1\n",
      "tensorboard                        2.9.1\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.8.1\n",
      "tensorflow                         2.9.1\n",
      "tensorflow-estimator               2.9.0\n",
      "tensorflow-hub                     0.12.0\n",
      "tensorflow-io-gcs-filesystem       0.26.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.9.4\n",
      "testpath                           0.5.0\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.7.2\n",
      "tinycss                            0.4\n",
      "toml                               0.10.2\n",
      "toolz                              0.11.1\n",
      "tornado                            6.1\n",
      "tqdm                               4.62.3\n",
      "traitlets                          5.1.0\n",
      "typed-ast                          1.4.3\n",
      "typing-extensions                  3.10.0.2\n",
      "typing-inspect                     0.9.0\n",
      "ujson                              4.0.2\n",
      "unicodecsv                         0.14.1\n",
      "Unidecode                          1.2.0\n",
      "uritemplate                        3.0.1\n",
      "urllib3                            1.26.7\n",
      "watchdog                           2.1.3\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           2.0.2\n",
      "wheel                              0.37.0\n",
      "whichcraft                         0.6.1\n",
      "widgetsnbextension                 3.5.1\n",
      "wrapt                              1.12.1\n",
      "wurlitzer                          2.1.1\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         3.0.1\n",
      "xlwings                            0.24.9\n",
      "xlwt                               1.3.0\n",
      "xmltodict                          0.12.0\n",
      "yapf                               0.31.0\n",
      "yarl                               1.9.2\n",
      "yfinance                           0.2.18\n",
      "zict                               2.0.0\n",
      "zipp                               3.6.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_raw = pd.read_csv('sentiment_stock_data.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution \n",
    "value_counts = stock_raw['Sentiment'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in a news\n",
    "def count_unique_words(sentence):\n",
    "    if isinstance(sentence, str):  # Check if the value is a string\n",
    "        # Split the sentence into words, convert to a set to remove duplicates, and count\n",
    "        return len(set(sentence.split()))\n",
    "    else:\n",
    "        # If the value is not a string, return 0 (or you could choose to return NaN)\n",
    "        return 0\n",
    "\n",
    "# Count the unique words in each row of the 'Sentence' column and create a new column with the counts\n",
    "stock_raw['Vocabulary_Count'] = stock_raw['Sentence'].apply(count_unique_words)\n",
    "\n",
    "# Display the DataFrame with the new 'Vocabulary_Count' column\n",
    "print(stock_raw[['Sentence', 'Vocabulary_Count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the mean, median, and max & min of the word count\n",
    "mean_count = stock_raw['Vocabulary_Count'].mean()\n",
    "median_count = stock_raw['Vocabulary_Count'].median()\n",
    "max_count = stock_raw['Vocabulary_Count'].max()\n",
    "min_count = stock_raw['Vocabulary_Count'].min()\n",
    "\n",
    "# Display the calculated statistics\n",
    "print(f\"Mean word count: {mean_count}\")\n",
    "print(f\"Median word count: {median_count}\")\n",
    "print(f\"Maximum word count: {max_count}\")\n",
    "print(f\"Minimum word count: {min_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text pre-processing\n",
    "\n",
    "## Simple text cleaning processes\n",
    "# 1. Clean missing values \n",
    "\n",
    "stock_raw.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d095d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To drop rows with N/A values and update the DataFrame in place:\n",
    "stock_cleaned = stock_raw.copy()\n",
    "stock_cleaned.dropna(inplace=True)\n",
    "\n",
    "# To assign the result to the same or a new DataFrame without using inplace:\n",
    "stock_cleaned = stock_cleaned.dropna()\n",
    "\n",
    "# To check for missing values again:\n",
    "missing_values_after_cleanup = stock_cleaned.isna().sum()\n",
    "missing_values_after_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4415f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. convert to lowercase, strip and remove punctuations\n",
    "\n",
    "\n",
    "testing_text=\"   This is a message to be cleaned. It may involve some things like: <br>, ?, :, ''  adjacent spaces and tabs.\"\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Return empty string if text is not a string\n",
    "\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    "preprocess(testing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "\n",
    "stopword(testing_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c52c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization \n",
    "\n",
    "\n",
    "# Downloading necessary NLTK data\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to convert NLTK's POS tags to WordNet's format\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Function to lemmatize a sentence with POS tagging\n",
    "def lemmatize_sentence_with_pos(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "    tokens = word_tokenize(sentence)\n",
    "    # Get POS tags for each token\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    # Lemmatize each word with its POS tag\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(pos)) for w, pos in pos_tags])\n",
    "    return lemmatized_output\n",
    "\n",
    "# Lemmatizing the test text with POS tagging\n",
    "lemmatized_text = lemmatize_sentence_with_pos(testing_text)\n",
    "print(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final pre-processing\n",
    "\n",
    "\n",
    "\n",
    "#FINAL PREPROCESSING\n",
    "# def finalpreprocess(string):\n",
    "#     return lemmatizer(stopword(preprocess(string)))\n",
    "\n",
    "\n",
    "def finalpreprocess(string):\n",
    "    # Step 1: Preprocess the text\n",
    "    preprocessed_text = preprocess(string)\n",
    "\n",
    "    # Step 2: Remove stopwords\n",
    "    text_without_stopwords = stopword(preprocessed_text)\n",
    "\n",
    "    # Step 3: Lemmatize the text with POS tagging\n",
    "    lemmatized_text = lemmatize_sentence_with_pos(text_without_stopwords)\n",
    "\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_cleaned['clean_Sentence'] = stock_cleaned['Sentence'].apply(lambda x: finalpreprocess(x))\n",
    "stock_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6666f",
   "metadata": {},
   "source": [
    "## Word Embedding/Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here use World2Vec because it better in capturing semantic info compared with \n",
    "BoW and TF-IDF, also this dataset is large enough for effective training.\"\"\"\n",
    "\n",
    "# I should've put in it in the very beginning\n",
    "!pip install -U gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# Step 1: Tokenize the sentences (assuming sentences are already cleaned and are separated by spaces)\n",
    "tokenized_sentences = [sentence.split() for sentence in stock_cleaned['clean_Sentence']]\n",
    "\n",
    "# Step 2: Train the Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 3: Function to vectorize a sentence based on the Word2Vec model\n",
    "def vectorize_sentence(sentence, model):\n",
    "    word_vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    # If the sentence is empty (no words found in the model), return a zero vector\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        # Otherwise, return the mean of the word vectors\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Step 4: Vectorize each sentence in the DataFrame\n",
    "stock_vector = stock_cleaned.copy()\n",
    "stock_vector['sentence_vector'] = stock_vector['clean_Sentence'].apply(lambda x: vectorize_sentence(x.split(), model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f0f2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the first few rows of the dataframe to confirm the 'sentence_vector' column exists\n",
    "\n",
    "stock_vector.head()\n",
    "# Also I have upgraded in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc088a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Also here I would like to try TF-IDF vectorization \n",
    "\n",
    "# stock_cleaned_tfidf = stock_cleaned.copy()\n",
    "\n",
    "# # Initialize vectorization\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# # Create TF-IDF features\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(stock_cleaned_tfidf['clean_Sentence'])\n",
    "\n",
    "# # Get feature names for the columns\n",
    "# try:\n",
    "#     # Try using the newer attribute available from version 0.24\n",
    "#     feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "# except AttributeError:\n",
    "#     # Fallback for older versions\n",
    "#     feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# # Create a DataFrame with the TF-IDF features\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# # Concatenate the original DataFrame with the new TF-IDF features\n",
    "# stock_cleaned_tfidf.reset_index(drop=True, inplace=True)\n",
    "# stock_cleaned_tfidf = pd.concat([stock_cleaned_tfidf, tfidf_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "My Kernel always die when run this \n",
    "too lazy to switch to a desktop\n",
    "so I'll ignore this at this stage \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33eea00",
   "metadata": {},
   "source": [
    "## Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd8229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the sentence_vector into training data and testing data\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(stock_vector[\"sentence_vector\"],\n",
    "                                                  stock_vector[\"Sentiment\"],\n",
    "                                                  test_size=0.2,\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n",
    "\n",
    "# Seem it has been successfully transformed to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28d40f",
   "metadata": {},
   "source": [
    "## ML Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da449351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "model_svm = svm.SVC(probability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup grid search parameter\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "}\n",
    "grid_search_svm = GridSearchCV(model_svm, param_grid, refit=True, verbose=2, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79144c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and tuning hyperparameters\n",
    "grid_search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4994f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
